#live api deployed at https://testingdeploy1307.herokuapp.com/

from flask import Flask, redirect
from flask import jsonify
from flask import request
from flask_pymongo import PyMongo
import os
import re
import copy
import string
from nltk.corpus import stopwords 
from nltk.tokenize import word_tokenize
#these were all the imports done for the program


#the ranking function ranks the documents/papers according to various parameters to give the most associated result
def ranking(lst, searched):
    lst2= copy.deepcopy(lst)
    try:
        a= int(searched)
    except:
        a = None

    for u in lst2:
        if a != None:
            if a == u['citations']:
                u['rank'] = u['rank']+ 690
        if searched == u['Title'].lower():
            u['rank'] = u['rank'] + 10000
        elif searched in u['Title'].lower():
            u['rank'] = u['rank'] + 1000

        if searched == u['authors'].lower():
            u['rank'] = u['rank'] + 600
        elif searched in u['authors'].lower():
            u['rank'] = u['rank'] + 585

        if searched == u['abstract'].lower():
            u['rank'] = u['rank'] + 300
        elif searched in u['abstract'].lower():
            u['rank'] = u['rank'] + 260

        if searched == u['journal domain'].lower():
            u['rank'] = u['rank'] + 195
        elif searched in u['journal domain'].lower():
            u['rank'] = u['rank'] + 150
    
    rank1 = sorted(lst2, key = lambda i : (i['rank'],i['citations']), reverse = True) #this sorts the documents in the list , with first priority to rank followed by priority to number of citations
    return rank1
 
    



#this is to indicate that it's a Flask application
app = Flask(__name__)

app.config['MONGO_DBNAME'] = 'restdb'
#this URI helps access the mongodb database, the password is autogenerated, but you can also choose your own password
app.config['MONGO_URI'] = 'mongodb+srv://RiXiRx:NLHFzEajQf2HQUR0@cluster0-3dbky.mongodb.net/trialBack7'

#this is to indicate its a pymongo app and helps access monogodb database using mongo
mongo = PyMongo(app)


#main page
@app.route('/')
def index():
    return 'This is home page request area'

#this is for searching amongst the medical papers by making a POST request from the client side
@app.route('/data/Medical/postreqALL',methods=['POST'])
def postdatareqMEDALL():
    try:
        rdata = mongo.db.resList #this accesses the collection resList in which all the papers were stored
        output = []
        search = request.json['search']
        search = search.lower() 
        search = re.sub(r"^\s+|\s+$", "", search) #this is to ignore spaces except between the words, so that extra spaces around the search phrase don't affect it
        try:
            a=float(search) #to check if the value searched was a number
        except:
            a= None
        REGX = re.compile(f".*{search}.*", re.I) #using Regex to search through a MongoDB database makes it faster to find documents
        #the search request is able to parse through various parameters using '$or' and the '$and' helps ensure the category is medical
        search_request = {                      
        '$and':[{
        '$or': [
            {'authors': {'$regex': REGX}},
            {'Title': {'$regex': REGX}},
            {'abstract':{'$regex': REGX}},
            {'journal domain':{'$regex':REGX}},
            {'citations':{'$eq':a}}
            ]},
        {'category':"Med"}
        ]}
        #this search request tries to find the exact match of the whole search phrase
        s= rdata.find(search_request).limit(100) #search documents have been limited to make the API faster in response, the ranking algorithm manages to give the most relevant results
        if s:
            for j in s:
                output.append({'Title' : j['Title'], 'authors' : j['authors'], 'journal domain': j['journal domain'], 'abstract': j['abstract'], 'link': j['link'], 'citations': j['citations'],'rank':0})
        ls = ranking(output, search)
        #the ranked output is assigned to the list ls for further use

        #here split up is done for all the words in the search term and stopwords is imported for further use
        stop_words = stopwords.words('english')
        stop_words.extend([',','.',';']) 
        words = search.split()
  
        #here the phrase is filtered and split , by removing stopwords and then used in searching
        filtered_sentence = [w for w in words if not w in stop_words]
        for k in filtered_sentence:
            REGX = re.compile(f".*{k}.*", re.I)
            search_request = {
        '$and':[{
        '$or': [
            {'authors': {'$regex': REGX}},
            {'Title': {'$regex': REGX}},
            {'abstract':{'$regex': REGX}},
            {'journal domain':{'$regex':REGX}},
            {'citations':{'$eq':a}}
            ]},
        {'category':"Med"}
        ]}
        #this is a repeat for parsing conditions but this time it searches for each of the words in the phrase and finds matches in the document

            s= rdata.find(search_request).limit(100) #here again the number of documents is limited for faster implementation
            for j in s:
                if list(filter(lambda item : item['Title'] == j['Title'], ls)):
                    ind = next((i for i, item in enumerate(ls) if item['Title'] == j['Title']), None)
                    ls[ind]['rank'] = ls[ind]['rank'] + 100
                    #if the paper is found again , it's rank is increased to increase it's relevance
                else:
                    ls.append({'Title' : j['Title'], 'authors' : j['authors'], 'journal domain': j['journal domain'], 'abstract': j['abstract'], 'link': j['link'], 'citations': j['citations'],'rank':0})
                    #if a paper is found for the first time, it's appended
            ls = ranking(ls,k)
            #again the ranking algorithm works to give best possible output

        #if the list contains 0  documents, it means no document exists regarding the search term     
        if len(ls)==0:
            return jsonify({'result':[{'Title' : "We are still looking for this paper", 'authors' : "Currently no details available", 'journal domain': "Currently no details available", 'abstract':"Currently no details available", 'link': "https://xorbians.wixsite.com/xorbians", 'citations': 0.0,'rank':0}]})
        return jsonify({'result': ls })
    except:
        return jsonify({'result':[{'Title' : "We are still looking for this paper", 'authors' : "Currently no details available", 'journal domain': "Currently no details available", 'abstract':"Currently no details available", 'link': "https://xorbians.wixsite.com/xorbians", 'citations': 0.0,'rank':0}]})


#this is for searching amongst the Non-medical papers by making a POST request from the client side
@app.route('/data/NonMedical/postreqALL',methods=['POST'])
def postdatareqNONMEDALL():
    try:
        rdata = mongo.db.resList #this accesses the collection resList in which all the papers were stored
        output = []
        search = request.json['search']
        search = search.lower()
        search = re.sub(r"^\s+|\s+$", "", search) #this is to ignore spaces except between the words, so that extra spaces around the search phrase don't affect it
        try:
            a=float(search) #to check if the value searched was a number
        except:
            a= None
        REGX = re.compile(f".*{search}.*", re.I) #using Regex to search through a MongoDB database makes it faster to find documents
        #the search request is able to parse through various parameters using '$or' and the '$and' helps ensure the category is non-medical
        search_request = {
        '$and':[{
        '$or': [
            {'authors': {'$regex': REGX}},
            {'Title': {'$regex': REGX}},
            {'abstract':{'$regex': REGX}},
            {'journal domain':{'$regex':REGX}},
            {'citations':{'$eq':a}}
            ]},
        {'category':"Non-Med"}
        ]}
        #this search request tries to find the exact match of the whole search phrase
        s= rdata.find(search_request).limit(100) #search documents have been limited to make the API faster in response, the ranking algorithm manages to give the most relevant results
        if s:
            
            for j in s:
                output.append({'Title' : j['Title'], 'authors' : j['authors'], 'journal domain': j['journal domain'], 'abstract': j['abstract'], 'link': j['link'], 'citations': j['citations'], 'rank':0})
        ls = ranking(output, search)
        #the ranked output is assigned to the list ls for further use

        #here split up is done for all the words in the search term and stopwords is imported for further use
        stop_words = stopwords.words('english')
        stop_words.extend([',','.',';'])
        words = search.split()

        #here the phrase is filtered and split , by removing stopwords and then used in searching 
        filtered_sentence = [w for w in words if not w in stop_words]
        for k in filtered_sentence:
            REGX = re.compile(f".*{k}.*", re.I)
            search_request = {
        '$and':[{
        '$or': [
            {'authors': {'$regex': REGX}},
            {'Title': {'$regex': REGX}},
            {'abstract':{'$regex': REGX}},
            {'journal domain':{'$regex':REGX}},
            {'citations':{'$eq':a}}
            ]},
        {'category':"Non-Med"}
        ]}
        #this is a repeat for parsing conditions but this time it searches for each of the words in the phrase and finds matches in the document

            s= rdata.find(search_request).limit(100) #here again the number of documents is limited for faster implementation
            for j in s:
                if list(filter(lambda item : item['Title'] == j['Title'], ls)):
                    ind = next((i for i, item in enumerate(ls) if item['Title'] == j['Title']), None)
                    ls[ind]['rank'] = ls[ind]['rank'] + 100
                    #if the paper is found again , it's rank is increased to increase it's relevance
                else:
                    ls.append({'Title' : j['Title'], 'authors' : j['authors'], 'journal domain': j['journal domain'], 'abstract': j['abstract'], 'link': j['link'], 'citations': j['citations'],'rank':0})
                    #if a paper is found for the first time, it's appended
            ls = ranking(ls,k)
            #again the ranking algorithm works to give best possible output
        
        #if the list contains 0  documents, it means no document exists regarding the search term 
        if len(ls)==0:
            return jsonify({'result':[{'Title' : "We are still looking for this paper", 'authors' : "Currently no details available", 'journal domain': "Currently no details available", 'abstract':"Currently no details available", 'link': "https://xorbians.wixsite.com/xorbians", 'citations': 0.0,'rank':0}]})
        return jsonify({'result': ls })
    except:
        return jsonify({'result':[{'Title' : "We are still looking for this paper", 'authors' : "Currently no details available", 'journal domain': "Currently no details available", 'abstract':"Currently no details available", 'link': "https://xorbians.wixsite.com/xorbians", 'citations': 0.0,'rank':0}]})


@app.route('/data/form',methods = ['GET'] )
def formRedirect():
    return redirect("https://forms.gle/jeSvN18Yxm2e313i9", code=302) #redirect to the google form for any rectification/community contribution


if __name__ == '__main__':
    port1 = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0' , port=port1)
